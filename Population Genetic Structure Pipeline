#Determining realized dispersal rates and comparing rates across taxa with different biological traits
#Pipeline developed for chapter 1 of masters thesis
#Pipeline is designed to determine realized dispersal rates for a variety of taxa, but the pipeline will be tested on Diptera species from various Arctic regions. 

#1.Loading Packages and Setting up Variables----

#Install and load needed packages 
#install.packages("apex")
library(apex)
#install.packages("coil")
library(coil)
#install.packages("data.table")
library(data.table)
#install_github("r-barnes/dggridR")
library(dggridR)
#install.packages("dplyr")
library(dplyr)
#install.packages("devtools")
library(devtools)
#install.packages("foreach")
library(foreach)
#install.packages("ggplot2")
library(ggplot2)
#install.packages("iNEXT")
library(iNEXT)
#install.packages("lwgeom")
library(lwgeom)
#install.packages("mmod")
library(mmod)
#install.packages("pegas")
library(pegas)
#install.packages("phylotools")
library(phylotools)
#install.packages("phytools")
library(phytools)
#install.packages("picante")
library(picante)
#install.packages("plot.matrix")
library(plot.matrix)
#install.packages("poppr")
library(poppr)
#install.packages("readr")
library(readr)
#install.packages("rlist")
library(rlist)
#install.packages("sf")
library(sf)
#install.packages("stringr")
library(stringr)
#install.packages("tidyr")
library(tidyr)
#install.packages("tidyverse")
library(tidyverse)
#BiocManager::install(c("Biostrings", "muscle", "DECIPHER"))
library(Biostrings)
library(muscle)
library(DECIPHER)

#Set distance matrix model. The TN93 model is used in this case. This model assumes different base frequencies and different mutation rates for transitions and transversions, as well as the different rates between pyrimidines and purines. 
model <- "TN93"
#Set additional clustering threshold. A clustering threshold of 0.04 is used in order to group closely related sequences together into clusters, while excluding more distantly related sequences. 
clustering_threshold <- 0.04 
#Set clustering method.UPGMA was chosen as the clustering method for my analysis. This method is fast, efficient, and commonly used. In this method, each distance contributes equally to the final result, and the averages are weighed by the number of taxa in the cluster. 
clustering_method <- "UPGMA"
#Set up taxa. 
taxa <- "Diptera"
#Set up study region 
region <- "Greenland"
#Set up reference sequence. This Diptera sequence was retrieved from BOLD (Record ID: ACGAZ1590-12, BIN:AAA1222). The BIN was chosen because it met the following criteria; from the order Diptera, contained at least 10 CO1-5P sequences, had at least one specimen photograph that matched the higher taxonomy and did not have taxonomic conflicts at family level or above. The reference sequence was chosen because it is 658 base pairs long, has 2 trace file chromatograms, and no missing information or stop codons. 
reference_sequence <- "AACTTTATATTTTATTTTTGGAGCTTGATCTAGAATAATTGGAACTTCTTTAAGAATATTAATTCGAATTGAATTAGGTCATCCAGGTTCCTTAATTGGAAATGACCAAATTTATAATGTAATTGTAACAGCTCATGCATTTATTATAATTTTTTTTATAGTAATACCAATTATAATTGGAGGATTTGGAAATTGATTAGTTCCTTTAATATTAGGAGCACCAGATATAGCTTTTCCTCGAATGAATAATATAAGTTTTTGACTTCTTCCTCCTGCTTTAATACTTTTATTAACAAGTAGAATAGTAGAAAGTGGAGCTGGAACAGGATGAACAGTTTATCCTCCTTTATCATCTATTATTGCTCATGGAGGAGCATCTGTTGACTTAGCTATTTTTTCTCTTCATTTAGCAGGAATTTCTTCTATTTTAGGAGCTGTAAATTTTATTACAACTGTAATTAATATACGATCTATTGGTATTACCTTTGATCGAATACCTTTATTTGTTTGATCAGTTGCTATTACAGCCTTATTACTTTTATTATCTTTACCAGTTTTAGCTGGAGCAATTACAATATTATTAACAGATCGAAATTTAAATACATCATTTTTTGATCCTGCTGGAGGAGGAGATCCTATTTTATACCAACATTTATTT"
#Set what size of polygon to be used in the study. A suitable range of sizes is. A size of 100 miles across was chosen in order to allow for smaller areas that still contained a suitable number of samples
Polygon_Length <- 50
#Set what percent the regions should be sampled to be included in the analysis. For my analysis, regions with 70% or more are included.
percent_sampled <- 0.7

#2.Extract Data from Databases-----

#Call data from BOLD. Currently just calling Diptera (fly) data from Greenland.Data was retrieved on June 24th 2021. 
#dfTaxa <- read_tsv("http://www.boldsystems.org/index.php/API_Public/combined?taxon=Diptera&geo=Greenland&format=tsv")
#Save data to a tsv file 
#write_tsv(dfTaxa, "GreenlandData")
#Read in the data
dfData <- read_tsv("GreenlandData")

#Read in data from GBIF. Greenland data retrieved from GBIF.org (23 June 2021) GBIF Occurrence Download https://doi.org/10.15468/dl.mk52hp
dfGeoData <- read_tsv("GreenlandGeo.csv")

#3. Filter Data----

#Filter the data 
dfData <- dfData %>%
  #Filter out records without bin_uri
  filter(str_detect(bin_uri, ":")) %>%
  #Filter out records without a sequence 
  filter(str_detect(nucleotides, "[ACTG]")) %>%
  #Filter for records with a COI-5P sequence
  filter(markercode == "COI-5P") %>%
  #Filter out sequences with fewer than 500 base pairs 
  filter(nchar(gsub("-", "", nucleotides)) > 499) %>%
  #Filter out records without a species name
  filter(!is.na(species_name))

#Filter out high gap/N content. A threshold of 1% was chosen because species often differ by more than 2% divergence. By filtering out records with > 1% N and gap content, we are likely to get a high-quality data set, given typical patterns of variability in COI in animals. 
startNGap <- sapply(regmatches(dfData$nucleotides, gregexpr("^[-N]", dfData$nucleotides)), length)
startNGap <- foreach(i=1:nrow(dfData)) %do% 
  if (startNGap[[i]]>0) { 
    split <- strsplit(dfData$nucleotides[i], "^[-N]+") 
    dfData$nucleotides[i] <- split[[1]][2]
  }
endNGap <- sapply(regmatches(dfData$nucleotides, gregexpr("[-N]$", dfData$nucleotides)), length)
endNGap <- foreach(i=1:nrow(dfData)) %do%
  if (endNGap[[i]]>0) {
    split <- strsplit(dfData$nucleotides[i], "[-N]+$")
    dfData$nucleotides[i] <- split[[1]][1]
  }
internalNGap <- sapply(regmatches(dfData$nucleotides, gregexpr("[-N]", dfData$nucleotides)), length)
internalNGap <- foreach(i=1:nrow(dfData)) %do%
  which((internalNGap[[i]]/nchar(dfData$nucleotides[i]) > 0.01))
nGapCheck <- sapply(internalNGap, function(x)length(x))
nGapCheck <- which(nGapCheck>0)
dfData <- dfData[-nGapCheck, ]

#Remove redundant "BOLD" section from each row in the BIN column 
dfData$bin_uri <- substr(dfData$bin_uri, 6, 13)

#Filter out sequences without coordinates 
containLatLon <- grep ("[0-9]", dfData$lat)
dfData <- dfData[containLatLon, ]

#Check for stop codons and indels.
#Save sequences to a list 
sequences <- as.list(dfData$nucleotides)
#Save record IDs as list 
processID <- as.list(dfData$processid)
#Look up translation table for your taxa
translation_table <- which_trans_table(taxa)
#Check for insertions and deletions
coi5p_object <- lapply(1:length(sequences), function(i){
  coi5p_pipe(sequences[[i]], trans_table = translation_table, name = processID[[i]], triple_translate = TRUE)
})
#See which sequences have indels and stop codons and remove these from the list 
indels <- list.exclude(coi5p_object, indel_likely == "TRUE")
stop_codon <- list.exclude(coi5p_object, stop_codons == "TRUE")
#Create a list of processids for remaining sequences
Ids_Filtered_Indels <- lapply(1:length(indels), function(i){
  indels[[i]]$name
})
Ids_Filtered_Stop <- lapply(1:length(indels), function(i){
  indels[[i]]$name
})
#Remove sequences with indels and stop codons from dataset
dfData <- dfData[dfData$processid %in% Ids_Filtered_Indels, ]
dfData <- dfData[dfData$processid %in% Ids_Filtered_Stop, ]

#Run some checks to ensure data is filtered properly
#Find dimensions of dataset
dim(dfData)
#Check that only CO1 is included 
unique(dfData$markercode)
#Check that there are no NAs
sum(is.na(dfData$bin_uri))
sum(is.na(dfData$species_name))
sum(is.na(dfData$nucleotides))
sum(is.na(dfData$lat))
#Find summary of seqeunce lengths 
summary(str_count(dfData$nucleotides))
#Find length of DNA sequences in the dataset 
Sequence_lengths <- str_count(dfData$nucleotides)
#Make a histogram to show the distributions of sequence lengths 
hist(Sequence_lengths, main = paste("Distribution of Sequence Lengths"), xlab = "Sequence Length")

#Filter the GBIF data
#Remove occurrences without a species ID
dfGeoData <- dfGeoData %>%
  filter(!is.na(species))

#Run some checks
#Find dimensions of dataset 
dim(dfGeoData)
#Check that there are no NAs
sum(is.na(dfGeoData$species))

#Reduce datasets to only needed columns 
dfData <- (dfData[, c("processid", "bin_uri", "species_name", "nucleotides", "lat", "lon")])
dfGeoData <- (dfGeoData[, c("gbifID", "species","decimalLatitude", "decimalLongitude")])

#Remove unneeded variables 
rm(endNGap, internalNGap, split, startNGap, containLatLon, i, nGapCheck, Sequence_lengths, coi5p_object, Ids_Filtered_Indels, Ids_Filtered_Stop, indels, processID, sequences, stop_codon, translation_table)

#4.Organizing Data by Clusters----

#If BOLD BINs are being used, the following steps are not needed.
#Place data into clusters using an additional distance threshold. 
#Split the dataset by family. Running several smaller alignments is much faster than running a large alignment. 
Alignment_List <- split(dfData, f = dfData$genus_name)

#Align and trim sequences with a reference sequence. The following parameters were chosen in order to conduct an accurate alignment. Iterations and refinements were set to 10 so that the tree and guide tree are being realigned multiple times and the best alignment is being kept. gapOpening is set to -3000 in order to reduce the gaps present in the alignment
RefSeqTrim <- function(x) {
  #Create data frame for reference sequence 
  #This reference sequence was taken from BOLD for Diptera (Record ID: ACGAZ1590-12, BIN:AAA1222).
  dfRefSeq <- data.frame(taxa= taxa, nucleotides= reference_sequence)
  colnames(dfRefSeq)[2] <- "nucleotides"
  #Convert to datatable
  dfRefSeq <- setDT(dfRefSeq)
  dfRefSeq[, "nucleotides":=as.character(nucleotides)]
  #Trim sequences to 620bp
  dfRefSeq[, nucleotides:=substr(nucleotides, 20, nchar(nucleotides)-19)]
  #Check sequence length
  dfRefSeq[, seqLength:=nchar(nucleotides)]
  #Ensure sequences are of character type
  alignmentSeqs <- as.character(x$nucleotides)
  #Name according to processid 
  names(alignmentSeqs) <- x$processid
  alignmentref <- as.character(dfRefSeq$nucleotides[1])
  #Name reference sequence 
  names(alignmentref) <- "Reference"
  #Put sequences together
  alignmentSeqsPlusRef <- append(alignmentref, alignmentSeqs)
  #Convert to DNAStringSet 
  DNAStringSet2 <- DNAStringSet(alignmentSeqsPlusRef)
  #Remove gaps
  DNAStringSet2 <- RemoveGaps(DNAStringSet2)
  #Run alignment 
  alignment2 <- AlignSeqs(DNAStringSet2, iterations = 10, refinements = 10, gapOpening = -3000)
  #Find stop and start positions in reference 
  refSeqPos <- which(alignment2@ranges@NAMES=="Reference")
  refSeqPos <- alignment2[refSeqPos]
  refSeqPosStart <- regexpr("[ACTG]", refSeqPos)
  refSeqPosStart <- as.numeric(refSeqPosStart)
  refSeqPosEnd <- nchar(dfRefSeq$nucleotides[1]) + refSeqPosStart
  refSeqPosEnd <- as.numeric(refSeqPosEnd)
  #Trim sequence
  alignment2Trimmed <- substr(alignment2, refSeqPosStart, refSeqPosEnd)
  #Convert to DNAStringSet
  DNAStringSet3 <- DNAStringSet(alignment2Trimmed)
  #Remove reference sequence 
  refSeqRm <- which(DNAStringSet3@ranges@NAMES=="Reference")
  dnaStringSet3 <- subset(DNAStringSet3[-refSeqRm])
  alignmentOrder <- DNAStringSet3@ranges@NAMES
  #Reorder based on alignment
  x <- x[match(alignmentOrder, x$processid), ]
  #Replace old sequences with new ones 
  trimmedSeqs <- as.character(DNAStringSet3)
  x$nucleotides <- trimmedSeqs
  #Return dataframe with new sequences 
  return(x)
}

#Trim sequences to reference sequence 
Data_alignment <- lapply(1:length(Alignment_List), function(i){
  RefSeqTrim(Alignment_List[[i]])
})
#Remove NAs 
Data_alignment <- lapply(1:length(Data_alignment), function(i){
  Data_alignment[[i]][-c(1), ]
})

#Merge Dataframes 
dfData_alignment <- bind_rows(Data_alignment)
#Set to dataframe
dfData_alignment <- as.data.frame(dfData_alignment)
#Check class of object 
class(dfData_alignment)

#Convert to DNAStringSet 
dfData_alignment$nucleotides <- DNAStringSet(dfData_alignment$nucleotides)
#Name the Stringset
names(dfData_alignment$nucleotides) <- dfData_alignment$processid

#Set name of alignment file
AlignmentName <- paste(region, "Alignment")
#Save alignment to file so it can be viewed in programs such as MEGA. 
writeXStringSet(dfData_alignment$nucleotides, file = AlignmentName, format = "fasta")

#Convert to dnaBin format 
dnaBIN <- as.DNAbin(dfData_alignment$nucleotides)
#Check that the class is correct
class(dnaBIN)

#Create a distance matrix.
distanceMatrix <- dist.dna(dnaBIN, model = model, as.matrix = TRUE, pairwise.deletion = TRUE)

#Cluster the sequences and plot the dendrogram
Data_clustered <- IdClusters(distanceMatrix,
                           method = clustering_method,
                           cutoff = clustering_threshold,
                           showPlot = TRUE,
                           type = "both",
                           verbose = TRUE)
#See how many clusters were created
length(unique(unlist(Data_clustered[[1]][1])))

#Extract the clustered dataframe
dfClusters <- Data_clustered[[1]]
#Set record IDs to a column instead of row names
dfClusters$processid <- row.names(dfClusters)
#Add clusters column to original dataframe
dfData_Clustered <- merge(dfClusters, dfData, by = "processid")

#Rename the dfData_Clustered in order to run the rest of the pipeline
dfData <- dfData_Clustered
#Reduce dataframe to needed columns 
dfData <- (dfData[, c("processid", "cluster", "species_name", "nucleotides", "lat", "lon")])
#Rename cluster to bin_uri just for simplicity 
names(dfData)[names(dfData) == "cluster"] <- "bin_uri"

#Remove any unneeded variables 
rm(Alignment_List, Data_alignment, Data_clustered,Data_stringset, dfData_alignment, dfRefSeq, dfClusters, distanceMatrix, dnaBIN, dfData_stringset)

#5.Group by Regions----

#Construct a grid of cells 
Grid <- dgconstruct(spacing=Polygon_Length, metric= TRUE, resround = 'down')

#Find corresponding grid cells for each record
dfData$cell <- dgGEO_to_SEQNUM(Grid, dfData$lon, dfData$lat)$seqnum

#Change nucleotide column back to a character string 
dfData$nucleotides <- as.character(dfData$nucleotides)

#Filter out BINs with less than 20 records and BINs that are only found in one region 
dfData <- dfData %>%
  group_by(bin_uri) %>%
  filter(n() > 19) %>%
  filter(length(unique(cell)) > 1)
#Ungroup the data
dfData <- ungroup(dfData, bin_uri)

#Filter out BINs with less than 10 records per region
dfData <- dfData %>%
  group_by(cell, bin_uri) %>%
  filter(n() > 9)
#Ungroup the data
dfData <- ungroup(dfData, cell, bin_uri)

#Filter out regions with less than 10 BINs
dfData <- dfData %>%
  group_by(cell) %>%
  filter(length(unique(bin_uri)) > 9)
#Ungroup the data
dfData <- ungroup(dfData, cell)

#Filter again for BINs that appear in more than one region, just to ensure that only these are included in the analysis
dfData <- dfData %>%
  group_by(bin_uri) %>%
  filter(length(unique(cell)) > 1)
#Ungroup the data
dfData <- ungroup(dfData, bin_uri)

#Calculate the abundance based species richness 
#Create a new dataframe with bin_uri and cells
dfRegions <- (dfData[, c("bin_uri", "cell")])
#Add column with the number of each records of each BIN at each site
dfRegions <- dfRegions %>%
  group_by(bin_uri, cell) %>%
  mutate(count=n())
#Filter down to only unique rows 
dfRegions <- filter(unique(dfRegions))
#Format the table so the regions the columns
dfRegions <- pivot_wider(dfRegions, names_from = cell, values_from = count)

#Remove columns with NAs
dfRegions <- na.omit(dfRegions)

#set to dataframe
dfRegions <- as.data.frame(dfRegions)
#Set bin_uri to rownames 
rownames(dfRegions) <- dfRegions[,1]
#Remove first column 
dfRegions$bin_uri <- NULL

#Find abundance based richness
abundance_results <- lapply(dfRegions, estimateR)
#Find incidence based richness
incidence_results <- lapply(dfRegions, specpool)

#Plot rarefaction curve
rarefaction_curve <- rarecurve(dfRegions)
#Plot species accumulation curve 
accumulation_curve <- specaccum(dfRegions)
plot(accumulation_curve)

#Filter for regions that do not meet the assigned expected species richness percentage. 
Sampled_Regions_Abundance <- list.filter(abundance_results,S.obs/S.chao1 >= percent_sampled_abundance)
Sampled_Regions_Incidence <- list.filter(abundance_results,S.obs/S.chao1 >= percent_sampled_incidence)

#Filter down to regions found in both lists
Sampled_Regions <- intersect(names(Sampled_Regions_Abundance), names(Sampled_Regions_Incidence))

#Filter dataset to include only well sampled regions
dfData <- filter(dfData, dfData$cell %in% Sampled_Regions)

#Count how many regions are included in the dataset
length(unique(dfData$cell))
#Count how many BINs are included in the dataset
length(unique(dfData$bin_uri))

#Get the center coordinates of the cells
SampleCenters  <- dgSEQNUM_to_GEO(Grid, dfData$cell)

#Get the number of samples in each cell
SampleCounts   <- dfData %>% group_by(cell) %>% summarise(count=n())

#Get the grid cell boundaries
dfGrid  <- dgcellstogrid(Grid, SampleCounts$cell, frame=TRUE, wrapcells=TRUE)
dfGrid <- merge(dfGrid, SampleCounts, by.x="cell", by.y="cell")

#Load map data
countries <- map_data("world")

#Plot polygons on a flat map. coord_fixed will need to be adjusted to focus in on your area of interest and scale_fill_viridis_c will need to be adjusted to reflect your sample size. 
Map <- ggplot() + 
  geom_polygon(data=countries, aes(x=long, y=lat, group=group), fill= "white", color="black") +
  geom_polygon(data=dfGrid, aes(x=long, y=lat, group=group, fill=count), alpha=0.4) +
  coord_fixed(xlim = c(-22, -18),  ylim = c(70, 80))+
  geom_path(data=dfGrid, aes(x=long, y=lat, group=group), alpha=0.4, color="white") +
  geom_point(aes(x=SampleCenters$lon_deg, y=SampleCenters$lat_deg)) +
  geom_label(aes(x=SampleCenters$lon_deg, y=SampleCenters$lat_deg, label = dfData$cell), size = 3.7, fontface = "bold", label.padding = unit(0.15, "lines")) +
  scale_fill_viridis_c(limits = c(1500, 8000)) +
  labs(fill = "Number of\nSpecimens") 

#Plot on a spherical projection
map_spherical <- Map + 
  coord_map("ortho", xlim = c(-23, -18), ylim = c(74, 75)) +
  xlab('')+ylab('')+
  theme(axis.ticks.x=element_blank())+
  theme(axis.ticks.y=element_blank())+
  theme(axis.text.x=element_blank())+
  theme(axis.text.y=element_blank())
  
#Split dataframe based on Bin_uri so each BIN can be analyzed individually
BIN_List <- split(dfData, f = dfData$bin_uri)

#Remove unneeded variables 
rm(abundance_results,accumulation_curve, dfRegions, Grid, countries, dfGrid, incidence_results, rarefaction_curve, SampleCenters, SampleCounts,Sampled_Regions_Abundance, Sampled_Regions_Incidence)

#6.Multiple Sequence Alignment----

#Alignment code was adapted from my previous work which was origionally adapted from Orton et al.(2019) and May et al.(2020). Code from both of these papers is avaliable at https://github.com/m-orton/Evolutionary-Rates-Analysis-Pipeline/blob/master/EvolutionaryComparisonPipelineSmallTaxa.R and https://github.com/jmay29/phylo/blob/master/refSeqTrim.R 
#Trim sequences to reference sequence 
Data_Trimmed <- lapply(1:length(BIN_List), function(i){
  RefSeqTrim(BIN_List[[i]])
})
#Remove NAs 
Data_Trimmed <- lapply(1:length(Data_Trimmed), function(i){
  Data_Trimmed[[i]][-c(1), ]
})

#Create final alignment of sequences 
#Create RefSeq data frame
dfRefSeq <- data.frame(taxa= taxa, nucleotides= reference_sequence)

#name nucleotide column and set as character 
colnames(dfRefSeq)[2] <- "nucleotides"
dfRefSeq$nucleotides <- as.character(dfRefSeq$nucleotides) 
#Trim references to standard 620
dfRefSeq$nucleotides <- substr(dfRefSeq$nucleotides, 20, nchar(dfRefSeq$nucleotides)-19) 
#Check sequence length
dfRefSeq$seqLength <- nchar(dfRefSeq$nucleotides)

#Extract sequences and process ID
processID <- lapply(1:length(Data_Trimmed), function(i){
  Data_Trimmed[[i]]$processid
})
Sequences <- lapply(1:length(Data_Trimmed), function(i){
  Data_Trimmed[[i]]$nucleotides
})
SequenceNames <- processID

#Take reference sequences
alignmentref <- as.character(dfRefSeq$nucleotides)
dfRefSeq$reference <- "reference"
#Name reference as a reference
alignmentRefNames <- dfRefSeq$reference
#Merge reference with other sequences
AlignmentSequencePlusRef <-lapply(1:length(Sequences), function(i){
  append(Sequences[[i]], alignmentref)
})

#Merge names together
AlignmentNames <-lapply(1:length(SequenceNames), function(i){
  append(SequenceNames[[i]], alignmentrefNames)
})

#Convert sequences to DNAStringSet format 
dnaStringSet3 <-lapply(1:length(AlignmentSequencePlusRef), function(i){
  DNAStringSet(AlignmentSequencePlusRef[[i]])
})

#Name each sequence 
for(i in 1:length(dnaStringSet3)){
  names(dnaStringSet3[[i]]) <- AlignmentNames[[i]] 
}

#Remove gaps
dnaStringSet3 <- lapply(1:length(dnaStringSet3), function(i){
  RemoveGaps(dnaStringSet3[[i]])
})

#Run alignment 
AlignmentFinal <- lapply(1:length(dnaStringSet3), function(i){
  AlignSeqs(dnaStringSet3[[i]], iterations = 10, refinements = 10, gapOpening = -3000)
})

#Convert to dnaStringSet format
dnaStringSet4 <- lapply(1:length(AlignmentFinal), function(i){
  DNAStringSet(AlignmentFinal[[i]])
})

#Save alignment to fasta file. View in another program such as Mega. 
#Create list of BINs
BINs <- lapply(1:length(BIN_List), function(i){
  unique(BIN_List[[i]]$bin_uri)
})
#Create name of fasta file
FastaFileNames <- lapply(1:length(BINs), function(i){
  paste(BINs[[i]], region, ".fas", sep="")
})
#Save alignment to fasta file. View in another program such as Mega.
AlignmentFinalFasta <- lapply(1:length(AlignmentFinal), function(i){
  DNAStringSet(AlignmentFinal[[i]])
})
foreach(i=1:length(AlignmentFinalFasta)) %do%
  writeXStringSet(AlignmentFinalFasta[[i]], file=FastaFileNames[[i]], format="fasta", width=1500)

#Convert DNAStringSet to dataframes
Data_Aligned <- lapply(1:length(dnaStringSet4), function(i){
  data.frame(seq=as.character(dnaStringSet4[[i]]), names=names(dnaStringSet4[[i]]))
})
#Rename names column
for(i in 1:length(Data_Aligned)){
  Data_Aligned[[i]]$processid <- Data_Aligned[[i]]$names 
}
Data_Aligned <- lapply(1:length(Data_Aligned), function(i){
  Data_Aligned[[i]][, c("processid", "seq")]
})
#Remove reference sequences
Reference_Filter <- lapply(1:length(Data_Aligned), function(i){
  which(!Data_Aligned[[i]]$processid == "reference")
})
for(i in 1:length(Reference_Filter)){
  Data_Aligned[[i]][Reference_Filter[[i]], ]
}

#Merge with the full data.
dfData_Full <- merge(dfData, dfData_Aligned, by = "processid")
Data_Full <- lapply(1:length(Data_Aligned), function(i){
  merge(BIN_List[[i]], Data_Aligned[[i]], by = "processid")
})

#Remove reference sequence
for(i in 1:length(FastaFileNames)){
  rm.sequence.fasta(FastaFileNames[[i]], FastaFileNames[[i]], to.rm = "reference")
}

#Remove unneeded variables 
rm(AlignmentFinal, AlignmentFinalFasta, AlignmentNames, AlignmentSequencePlusRef, BINs, Data_Aligned,Data_Trimmed, dfRefSeq, dnaStringSet3, dnaStringSet4, processID, Reference_Filter, SequenceNames, Sequences, alignmentRefNames, alignmentref)

#7.F-Statistics and Multi-allelic Measures----

#Read in fasta files
seq_multiFas <- lapply(1:length(FastaFileNames), function(i){
  read.multiFASTA(FastaFileNames[[i]])
})

#Plot the alignments
for(i in 1:length(seq_multiFas)){
  plot(seq_multiFas[[i]], cex = 0.2)
}

#Remove .fas from locus name
for(i in 1:length(seq_multiFas)){
  (setLocusNames(seq_multiFas[[i]]) <- gsub(".fas", "", getLocusNames(seq_multiFas[[i]])))
}

#Convert to genind object
seq_genind <- lapply(1:length(seq_multiFas), function(i){
  multidna2genind(seq_multiFas[[i]], mlst = TRUE)
})
#Check class of object
class(seq_genind[[1]])
#Look at summary of object 
summary(seq_genind[[1]])

#Create dataframe for labels for the genind object. Running into errors with this. 
Names <- data.frame(Species = seqs_multiFas@labels, order = 1:length(seqs_multiFas@labels))
Names <- lapply(1:length(seq_multiFas), function(i){
  data.frame(processid = seq_multiFas[[i]]@labels, order = 1:length(seq_multiFas[[i]]@labels))
})

#Create dataframe containing only the record id and population 
Data_Reduced <- lapply(1:length(Data_Full), function(i){
  Data_Full[[i]][,c("processid", "cell")]
})

#Merge the two dataframes by record id
Data_Reduced <- lapply(1:length(Data_Reduced), function(i){
  merge(Data_Reduced[[i]], Names[[i]])
})

#Ensure dataframe is in the same order as the alignment
Data_Reduced <- lapply(1:length(Data_Reduced), function(i){
  Data_Reduced[[i]][order(Data_Reduced[[i]]$order), ]
})

#Create dataframe for regions/cells
Populations <- lapply(1:length(Data_Reduced), function(i){
  data.frame(Populations = Data_Reduced[[i]]$cell)
})

#Assign populations to genind object
for(i in 1:length(seq_genind)){
  strata(seq_genind[[i]]) <- Populations[[i]]
}
#Check to make sure populations are assigned properly 
seq_genind[[1]]$strata
#Specify that we want to compare the populations we inputted
for(i in 1:length(seq_genind)){
  setPop(seq_genind[[i]]) <- ~Populations
}

#Calculate population genetic differentiation. This function finds the expected heterozygosity if there is random mating within sub-populations, the expected heterozygosity if there were random mating across the global population, Nei's Gst, Hedrick's Gst and Jost's D.
stat_summaries <- lapply(1:length(seq_genind), function(i){
  diff_stats(seq_genind[[i]])
})

#Calculate Jost's D
DPairwise <- lapply(1:length(seq_genind), function(i){
  as.matrix(pairwise_D(seq_genind[[i]]))
})
#Calculate pairwise FST
NeiPairwise <- lapply(1:length(seq_genind), function(i){
  as.matrix(pairwise_Gst_Nei(seq_genind[[i]]))
})
#Calculate GST
HedrickPairwise <- lapply(1:length(seq_genind), function(i){
  as.matrix(pairwise_Gst_Hedrick(seq_genind[[i]]))
})

#Plot Jost's D as a heat map 
#Set matrices as dataframes 
DDataframe <- lapply(1:length(DPairwise), function(i){
  as.data.frame(DPairwise[[i]])
})
#Plot Heat map
HeatMaps_JD <- lapply(1:length(DDataframe), function(i){
  DDataframe[[i]] %>% 
    as.data.frame() %>%
    rownames_to_column("Populations") %>%
    pivot_longer(-c(Populations), names_to = "samples", values_to = "JD")%>%
    mutate(samples= fct_relevel(samples, colnames(DDataframe[[i]]))) %>%
    mutate(Populations = fct_relevel(Populations, colnames(DDataframe[[i]]))) %>%
    ggplot(aes(x=samples, y=Populations, fill=JD)) + 
    geom_raster() +
    xlab("Populations") +
    labs(fill = "Jost's D")
})

#Plot FST as a heat map 
#Set matrices as dataframes 
NeiDataframe <- lapply(1:length(NeiPairwise), function(i){
  as.data.frame(NeiPairwise[[i]])
})
#Plot Heat map
HeatMaps_FST <- lapply(1:length(NeiDataframe), function(i){
  NeiDataframe[[i]] %>% 
    as.data.frame() %>%
    rownames_to_column("Populations") %>%
    pivot_longer(-c(Populations), names_to = "samples", values_to = "FST")%>%
    mutate(samples= fct_relevel(samples, colnames(NeiDataframe[[i]]))) %>%
    mutate(Populations = fct_relevel(Populations, colnames(NeiDataframe[[i]]))) %>%
    ggplot(aes(x=samples, y=Populations, fill=FST)) + 
    geom_raster() +
    xlab("Populations") +
    labs(fill = "FST")
})

#Plot GST as a heat map 
#Set matrices as dataframes 
HedrickDataframe <- lapply(1:length(HedrickPairwise), function(i){
  as.data.frame(HedrickPairwise[[i]])
})
#Plot Heat map
HeatMaps_GST <- lapply(1:length(HedrickDataframe), function(i){
  HedrickDataframe[[i]] %>% 
    as.data.frame() %>%
    rownames_to_column("Populations") %>%
    pivot_longer(-c(Populations), names_to = "samples", values_to = "GST")%>%
    mutate(samples= fct_relevel(samples, colnames(HedrickDataframe[[i]]))) %>%
    mutate(Populations = fct_relevel(Populations, colnames(HedrickDataframe[[i]]))) %>%
    ggplot(aes(x=samples, y=Populations, fill=GST)) + 
    geom_raster() +
    xlab("Populations") +
    labs(fill = "GST")
})

#Remove uneeded variables
rm(Data_Reduced, FastaFileNames, Names, Populations, seq_multiFas)

#8.Analysis of Molecular Variance (AMOVA)----

#Calculate Analysis of Molecular Variance 
AMOVA <- lapply(1:length(seq_genind), function(i){
  poppr.amova(seq_genind[[i]], ~Populations)
})

#9.Mismatch Distributions----

#Put sequences into DNABin format
#First convert sequences to a DNAStringSet format
Data_StringSet <- lapply(1:length(Data_Full), function(i){
  DNAStringSet(Data_Full[[i]]$seq)
})
for(i in 1:length(Data_Full)){
  names(Data_StringSet[[i]]) <- Data_Full[[i]]$processid
}
Data_DNABin <- lapply(1:length(Data_StringSet), function(i){
  as.DNAbin(Data_StringSet[[i]])
})
#Check that the format is correct
class(Data_DNABin[[1]])

#Calculate mismatch distribution for the sequences and plot a histogram 
MD <- lapply(1:length(Data_DNABin), function(i){
  MMD(Data_DNABin[[i]], xlab = "Pairwise Distance")
})

#10.Analysis of Variance (ANOVA)----

#Read in csv file containing trait information and FST values. Commented out flight ability for now because all species looked at in this dataset have a flying life stage. If using clustered data, read in the second commented out dataframe.
Trait_Data <- read_csv(file="C:/Users/sammi/OneDrive/Documents/Diptera_Trait_Data2.csv")
#Trait_Data <- read_csv(file="C:/Users/sammi/OneDrive/Documents/Diptera_Trait_Data_Clustered.csv")
#Run ANOVAs for all traits compared to FST
ANOVA_Feeding_Adult_FST <- aov(FST ~ adult_diet, data = Trait_Data)
ANOVA_Feeding_Larval_FST <- aov(FST ~ larval_diet, data = Trait_Data)
ANOVA_Habitat_FST <- aov(FST ~ habitat, data = Trait_Data)
#ANOVA_Flight_FST <- aov(FST ~ flight_ability, data = Trait_Data)
#Get ANOVA summary 
summary(ANOVA_Habitat_FST)
summary(ANOVA_Feeding_Adult_FST)
summary(ANOVA_Feeding_Larval_FST)
#summary(ANOVA_Flight_FST)

#Run ANOVAs for all traits compared to GST
ANOVA_Feeding_Adult_GST <- aov(GST ~ adult_diet, data = Trait_Data)
ANOVA_Feeding_Larval_GST <- aov(GST ~ larval_diet, data = Trait_Data)
ANOVA_Habitat_GST <- aov(GST ~ habitat, data = Trait_Data)
#ANOVA_Flight_GST <- aov(GST ~ flight_ability, data = Trait_Data)
#Get ANOVA summary 
summary(ANOVA_Habitat_GST)
summary(ANOVA_Feeding_Adult_GST)
summary(ANOVA_Feeding_Larval_GST)
#summary(ANOVA_Flight_GST)

#Run ANOVAs for all traits compared to JD
ANOVA_Feeding_Adult_JD <- aov(JD ~ adult_diet, data = Trait_Data)
ANOVA_Feeding_Larval_JD <- aov(JD ~ larval_diet, data = Trait_Data)
ANOVA_Habitat_JD <- aov(JD ~ habitat, data = Trait_Data)
#ANOVA_Flight_JD <- aov(JD ~ flight_ability, data = Trait_Data)
#Get ANOVA summary 
summary(ANOVA_Habitat_JD)
summary(ANOVA_Feeding_Adult_JD)
summary(ANOVA_Feeding_Larval_JD)
#summary(ANOVA_Flight_JD)

#Plot results as violin plots
#FST and adult diet
p <- ggplot(Trait_Data, aes(x=Trait_Data$adult_diet, y=Trait_Data$FST, fill=Trait_Data$adult_diet)) + 
  geom_violin(trim=FALSE, legend = NULL)
p + scale_color_brewer(palette = "Dark2")
#FST and larval diet
p <- ggplot(Trait_Data, aes(x=Trait_Data$larval_diet, y=Trait_Data$FST, fill=Trait_Data$larval_diet)) + 
  geom_violin(trim=FALSE, legend = NULL)
p + scale_color_brewer(palette = "Dark2")
#FST and habitat
p <- ggplot(Trait_Data, aes(x=Trait_Data$habitat, y=Trait_Data$FST, fill=Trait_Data$habitat)) + 
  geom_violin(trim=FALSE, legend = NULL)
p + scale_color_brewer(palette = "Dark2")

#GST and adult diet
p <- ggplot(Trait_Data, aes(x=Trait_Data$adult_diet, y=Trait_Data$GST, fill=Trait_Data$adult_diet)) + 
  geom_violin(trim=FALSE, legend = NULL)
p + scale_color_brewer(palette = "Dark2")
#GST and larval diet
p <- ggplot(Trait_Data, aes(x=Trait_Data$larval_diet, y=Trait_Data$GST, fill=Trait_Data$larval_diet)) + 
  geom_violin(trim=FALSE, legend = NULL)
p + scale_color_brewer(palette = "Dark2")
#GST and habitat
p <- ggplot(Trait_Data, aes(x=Trait_Data$habitat, y=Trait_Data$GST, fill=Trait_Data$habitat)) + 
  geom_violin(trim=FALSE, legend = NULL)
p + scale_color_brewer(palette = "Dark2")

#Jost's D and adult diet
p <- ggplot(Trait_Data, aes(x=Trait_Data$adult_diet, y=Trait_Data$JD, fill=Trait_Data$adult_diet)) + 
  geom_violin(trim=FALSE, legend = NULL)
p + scale_color_brewer(palette = "Dark2")
#Jost's D and larval diet
p <- ggplot(Trait_Data, aes(x=Trait_Data$larval_diet, y=Trait_Data$JD, fill=Trait_Data$larval_diet)) + 
  geom_violin(trim=FALSE, legend = NULL)
p + scale_color_brewer(palette = "Dark2")
#Jost's D and habitat
p <- ggplot(Trait_Data, aes(x=Trait_Data$habitat, y=Trait_Data$JD, fill=Trait_Data$habitat)) + 
  geom_violin(trim=FALSE, legend = NULL)
p + scale_color_brewer(palette = "Dark2")

#11.Phylogenetic Generalized Least Squares Analysis (PGLS)----

#Read in phylogenetic tree. This tree was created based on the literature and assembled by hand using the program Mesquite. If using the clustered data, read in the second tree.
PGLStree <- read.nexus("GreenlandDipteraTreeBIN_Oct4")
#PGLStree <- read.nexus("DipteraClusteredTree")
#Set branch lengths to one
PGLStree$edge.length <- replicate((length(PGLStree$edge[, 1])), 1)
PGLStree <- force.ultrametric(PGLStree, method="extend")

#Run PGLS for FST
#Set the row names to BINS. If using clustered data, use the commented code and set row names to species names, as the tip labels of the tree cannot be numeric.  
Trait_Data <- Trait_Data %>%
  column_to_rownames(var = 'BIN')
#Trait_Data <- Trait_Data %>%
#  column_to_rownames(var = 'Species')
#Make sure tree and dataframe are in the same order
Trait_Data <- Trait_Data[match(PGLStree$tip.label, rownames(Trait_Data)), ]
#Run PGLS analysis 
pglsModel_Habitat_FST <- gls(FST ~ habitat, correlation = corBrownian(phy = PGLStree), data = Trait_Data, method = "ML")
pglsModel_Adult_Diet_FST <- gls(FST ~ adult_diet, correlation = corBrownian(phy = PGLStree), data = Trait_Data, method = "ML")
pglsModel_Larval_Diet_FST <- gls(FST ~ larval_diet, correlation = corBrownian(phy = PGLStree), data = Trait_Data, method = "ML")
#pglsModel_Flight_FST <- gls(FST ~ flight_ability, correlation = corBrownian(phy = PGLStree), data = Trait_Data, method = "ML")
#Get PGLS summary 
summary(pglsModel_Habitat_FST)
summary(pglsModel_Adult_Diet_FST)
summary(pglsModel_Larval_Diet_FST)
#summary(pglsModel_Flight_FST)

#Create boxplots for traits vs. population genetic structure metrics 
plot_Habitat_FST<- boxplot(Trait_Data$FST ~ Trait_Data$habitat)
plot_Adult_Diet_FST <- boxplot(Trait_Data$FST ~ Trait_Data$adult_diet)
plot_Larval_Diet_FST <- boxplot(Trait_Data$FST ~ Trait_Data$larval_diet)
#plot_Flight_FST <- boxplot(Trait_Data$FST ~ Trait_Data$flight_ability)

#Run PGLS for GST
pglsModel_Habitat_GST <- gls(GST ~ habitat, correlation = corBrownian(phy = PGLStree), data = Trait_Data, method = "ML")
pglsModel_Adult_Diet_GST <- gls(GST ~ adult_diet, correlation = corBrownian(phy = PGLStree), data = Trait_Data, method = "ML")
pglsModel_Larval_Diet_GST <- gls(GST ~ larval_diet, correlation = corBrownian(phy = PGLStree), data = Trait_Data, method = "ML")
#pglsModel_Flight_GST <- gls(GST ~ flight_ability, correlation = corBrownian(phy = PGLStree), data = Trait_Data, method = "ML")
#Get PGLS summary 
summary(pglsModel_Habitat_GST)
summary(pglsModel_Adult_Diet_GST)
summary(pglsModel_Larval_Diet_GST)
#summary(pglsModel_Flight_GST)

#Create boxplots for traits vs. population genetic structure metrics 
plot_Habitat_GST<- boxplot(Trait_Data$GST ~ Trait_Data$habitat)
plot_Adult_Diet_GST <- boxplot(Trait_Data$GST ~ Trait_Data$adult_diet)
plot_Larval_Diet_GST <- boxplot(Trait_Data$GST ~ Trait_Data$larval_diet)
#plot_Flight_GST <- boxplot(Trait_Data$GST ~ Trait_Data$flight_ability)

#Run PGLS for JD
#Run PGLS analysis 
pglsModel_Habitat_JD <- gls(JD ~ habitat, correlation = corBrownian(phy = PGLStree), data = Trait_Data, method = "ML")
pglsModel_Adult_Diet_JD <- gls(JD ~ adult_diet, correlation = corBrownian(phy = PGLStree), data = Trait_Data, method = "ML")
pglsModel_Larval_Diet_JD <- gls(JD ~ larval_diet, correlation = corBrownian(phy = PGLStree), data = Trait_Data, method = "ML")
#pglsModel_Flight_JD <- gls(JD ~ flight_ability, correlation = corBrownian(phy = PGLStree), data = Trait_Data, method = "ML")
#Get PGLS summary 
summary(pglsModel_Habitat_JD)
summary(pglsModel_Adult_Diet_JD)
summary(pglsModel_Larval_Diet_JD)
#summary(pglsModel_Flight_JD)

#Create boxplots for traits vs. population genetic structure metrics 
plot_Habitat_JD<- boxplot(Trait_Data$JD ~ Trait_Data$habitat)
plot_Adult_Diet_JD <- boxplot(Trait_Data$JD ~ Trait_Data$adult_diet)
plot_Larval_Diet_JD <- boxplot(Trait_Data$JD ~ Trait_Data$larval_diet)
#plot_Flight_JD <- boxplot(Trait_Data$JD ~ Trait_Data$flight_ability)

#12.Determining Range Size----

#Reduce dfData_Full to needed columns
dfData_Full <- (dfData_Full[, c("processid", "species_name", "lat", "lon")])

#Rename the columns so that they are consistent across both dataframes {
names(dfData)[names(dfData) == "processid"] <- "ID"
names(dfGeoData)[names(dfGeoData) == "gbifID"] <- "ID"
names(dfGeoData)[names(dfGeoData) == "species"] <- "species_name"
names(dfGeoData)[names(dfGeoData) == "decimalLatitude"] <- "lat"
names(dfGeoData)[names(dfGeoData) == "decimalLongitude"] <- "lon"

#Reduce dfGeoData to only species found in dfData
Data_Filter <- which(dfGeoData$species_name %in% dfData$species_name)
dfGeoData <- dfGeoData[Data_Filter, ]

#Combine dataframes
dfRange_Data <- rbind(dfData_Full, dfGeoData)

#Split into list of dataframes by species
Species_List <- split(dfRange_Data, f = dfRange_Data$species_name)

#Find the range size.Code adapted from https://stackoverflow.com/questions/48383990/convert-sequence-of-longitude-and-latitude-to-polygon-via-sf-in-r
Area <- lapply(1:length(Species_List), function(i){
  Species_List[[i]] %>%
    #Covert coordinates to point geometries
    st_as_sf(coords = c("lon", "lat"), crs = 4326) %>%
    #Combine points into a multipoint
    summarise(geometry = st_combine(geometry)) %>%
    #convert to a polygon
    st_cast("POLYGON") %>%
    #Calculate area 
    st_area()
})

#Remove unneeded variables
rm(Data_Filter)

#13. Relationship between F-Statistics, Range size and Traits----

#Read in range size data. If using clustered data, read in the second file. 
Range_Data <- read_csv(file="C:/Users/sammi/OneDrive/Documents/Range_Data.csv")
#Range_Data <- read_csv(file="C:/Users/sammi/OneDrive/Documents/Range_Data_Clustered.csv")

#Run an ANOVA and PGLS to compare range size to traits and population genetic structure 
#Run ANOVA comparing range size to population genetic stucture metrics 
ANOVA_Range_FST <- aov(range_size ~ FST, data = Range_Data)
ANOVA_Range_GST <- aov(range_size ~ GST, data = Range_Data)
ANOVA_Range_JD <- aov(range_size ~ JD, data = Range_Data)
#Get ANOVA summary 
summary(ANOVA_Range_FST)
summary(ANOVA_Range_GST)
summary(ANOVA_Range_JD)

#Run ANOVA comparing range size to traits 
ANOVA_Range_Adult <- aov(range_size ~ adult_diet, data = Range_Data)
ANOVA_Range_Larval <- aov(range_size ~ larval_diet, data = Range_Data)
ANOVA_Range_Habitat<- aov(range_size ~ habitat, data = Range_Data)
#ANOVA_Range_Flight <- aov(range_size ~ flight_ability, data = Range_Data)
#Get ANOVA summary 
summary(ANOVA_Range_Habitat)
summary(ANOVA_Range_Adult)
summary(ANOVA_Range_Larval)
#summary(ANOVA_Range_Flight)

#Plot results as violin plots
#Range size and adult diet
p <- ggplot(Range_Data, aes(x=Range_Data$adult_diet, y=Range_Data$range_size, fill=Range_Data$adult_diet)) + 
  geom_violin(trim=FALSE, legend = NULL)
p + scale_color_brewer(palette = "Dark2")
#Range size and larval diet
p <- ggplot(Range_Data, aes(x=Range_Data$larval_diet, y=Range_Data$range_size, fill=Range_Data$larval_diet)) + 
  geom_violin(trim=FALSE, legend = NULL)
p + scale_color_brewer(palette = "Dark2")
#Range size and habitat
p <- ggplot(Range_Data, aes(x=Range_Data$habitat, y=Range_Data$range_size, fill=Range_Data$habitat)) + 
  geom_violin(trim=FALSE, legend = NULL)
p + scale_color_brewer(palette = "Dark2")

#Load in tree. This is the same as the other phylogenetic tree, but with species names as tip labels instead of BINS. If using clustered data, just use species tree from earlier.
PGLStree <- read.nexus("DipteraSpeciesTree_Aug26")
#Set branch lengths to one
PGLStree$edge.length <- replicate((length(PGLStree$edge[, 1])), 1)
PGLStree <- force.ultrametric(PGLStree, method="extend")

#Set the row names to species names 
Range_Data <- Range_Data %>%
  column_to_rownames(var = 'species_name')
#Make sure tree and dataframe are in the same order
Range_Data <- Range_Data[match(PGLStree$tip.label, rownames(Range_Data)), ]

#Run PGLS comparing metrics of population genetic structure to range size
pglsModel_Range_FST <- gls(range_size ~ FST, correlation = corBrownian(phy = PGLStree), data = Range_Data, method = "ML")
pglsModel_Range_GST <- gls(range_size ~ GST, correlation = corBrownian(phy = PGLStree), data = Range_Data, method = "ML")
pglsModel_Range_JD <- gls(range_size ~ JD, correlation = corBrownian(phy = PGLStree), data = Range_Data, method = "ML")
#Get PGLS summary 
summary(pglsModel_Range_FST)
summary(pglsModel_Range_GST)
summary(pglsModel_Range_JD)

#Run PGLS analysis 
pglsModel_Range_Habitat <- gls(range_size ~ habitat, correlation = corBrownian(phy = PGLStree), data = Range_Data, method = "ML")
pglsModel_Range_Adult <- gls(range_size ~ adult_diet, correlation = corBrownian(phy = PGLStree), data = Range_Data, method = "ML")
pglsModel_Range_Larval <- gls(range_size ~ larval_diet, correlation = corBrownian(phy = PGLStree), data = Range_Data, method = "ML")
#pglsModel_Range_Flight <- gls(range_size ~ flight_ability, correlation = corBrownian(phy = PGLStree), data = Range_Data, method = "ML")
#Get PGLS summary 
summary(pglsModel_Range_Habitat)
summary(pglsModel_Range_Adult)
summary(pglsModel_Range_Larval)
#summary(pglsModel_Range_Flight)

#Create boxplots for range size vs. traits
plot_Range_Habitat <- boxplot(Range_Data$range_size ~ Range_Data$habitat)
plot_Range_Adult <- boxplot(Range_Data$range_size ~ Range_Data$adult_diet)
plot_Range_Larval <- boxplot(Range_Data$Range_size ~ Range_Data$larval_diet)
#plot_Range_Flight <- boxplot(Range_Data$range_size ~ Range_Data$flight_ability)
