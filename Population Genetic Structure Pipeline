#Determining realized dispersal rates and comparing rates across taxa with different biological traits
#Pipeline developed for chapter 1 of masters thesis
#Pipeline is designed to determine realized dispersal rates for a variety of taxa, but the pipeline will be tested on Diptera species from various Arctic regions. 

#1.Loading Packages and Setting up Variables----

#Install and load needed packages 
#install.packages("apex")
library(apex)
#install.packages("coil")
library(coil)
#install.packages("data.table")
library(data.table)
#install.packages("dplyr")
library(dplyr)
#install.packages("foreach")
library(foreach)
#install.packages("ggplot2")
library(ggplot2)
#install.packages("devtools")
library(devtools)
#install_github("r-barnes/dggridR")
library(dggridR)
#install.packages("tidyr")
library(tidyr)
#install.packages("iNEXT")
library(iNEXT)
#install.packages("phylotools")
library(phylotools)
#install.packages("readr")
library(readr)
#install.packages("rlist")
library(rlist)
#install.packages("stringr")
library(stringr)
#BiocManager::install(c("Biostrings", "muscle", "DECIPHER"))
library(Biostrings)
library(muscle)
library(DECIPHER)

#Set distance matrix model. The TN93 model is used in this case. This model assumes different base frequencies and different mutation rates for transitions and transversions, as well as the different rates between pyrimidines and purines. 
model <- "TN93"
#Set additional clustering threshold. A clustering threshold of 0.04 is used in order to group closely related sequences together into clusters, while excluding more distantly related sequences. 
clustering_threshold <- 0.04 
#Set clustering method.UPGMA was chosen as the clustering method for my analysis. This method is fast, efficient, and commonly used. In this method, each distance contributes equally to the final result, and the averages are weighed by the number of taxa in the cluster. 
clustering_method <- "UPGMA"
#Set up taxa. 
taxa <- "Diptera"
#Set up study region 
region <- "Greenland"
#Set up reference sequence. This Diptera sequence was retrieved from BOLD (Record ID: ACGAZ1590-12, BIN:AAA1222). The BIN was chosen because it met the following criteria; from the order Diptera, contained at least 10 CO1-5P sequences, had at least one specimen photograph that matched the higher taxonomy and did not have taxonomic conflicts at family level or above. The reference sequence was chosen because it is 658 base pairs long, has 2 trace file chromatograms, and no missing information or stop codons. 
reference_sequence <- "AACTTTATATTTTATTTTTGGAGCTTGATCTAGAATAATTGGAACTTCTTTAAGAATATTAATTCGAATTGAATTAGGTCATCCAGGTTCCTTAATTGGAAATGACCAAATTTATAATGTAATTGTAACAGCTCATGCATTTATTATAATTTTTTTTATAGTAATACCAATTATAATTGGAGGATTTGGAAATTGATTAGTTCCTTTAATATTAGGAGCACCAGATATAGCTTTTCCTCGAATGAATAATATAAGTTTTTGACTTCTTCCTCCTGCTTTAATACTTTTATTAACAAGTAGAATAGTAGAAAGTGGAGCTGGAACAGGATGAACAGTTTATCCTCCTTTATCATCTATTATTGCTCATGGAGGAGCATCTGTTGACTTAGCTATTTTTTCTCTTCATTTAGCAGGAATTTCTTCTATTTTAGGAGCTGTAAATTTTATTACAACTGTAATTAATATACGATCTATTGGTATTACCTTTGATCGAATACCTTTATTTGTTTGATCAGTTGCTATTACAGCCTTATTACTTTTATTATCTTTACCAGTTTTAGCTGGAGCAATTACAATATTATTAACAGATCGAAATTTAAATACATCATTTTTTGATCCTGCTGGAGGAGGAGATCCTATTTTATACCAACATTTATTT"
#Set what size of polygon to be used in the study. A suitable range of sizes is. A size of 100 miles across was chosen in order to allow for smaller areas that still contained a suitable number of samples
Polygon_Length <- 50
#Set what percent the regions should be sampled to be included in the analysis. For my analysis, regions with 70% or more are included.
percent_sampled <- 0.7

#2.Extract Data from Databases-----

#Call data from BOLD. Currently just calling Diptera (fly) data from Greenland.Data was retrieved on June 24th 2021. 
#dfTaxa <- read_tsv("http://www.boldsystems.org/index.php/API_Public/combined?taxon=Diptera&geo=Greenland&format=tsv")
#Save data to a tsv file 
#write_tsv(dfTaxa, "GreenlandData")
#Read in the data
dfData <- read_tsv("GreenlandData")

#Read in data from GBIF. Greenland data retrieved from GBIF.org (23 June 2021) GBIF Occurrence Download https://doi.org/10.15468/dl.mk52hp
dfGeoData <- read_tsv("GreenlandGeo.csv")

#3. Filter Data----

#Filter the data 
dfData <- dfData %>%
  #Filter out records without bin_uri
  filter(str_detect(bin_uri, ":")) %>%
  #Filter out records without a sequence 
  filter(str_detect(nucleotides, "[ACTG]")) %>%
  #Filter for records with a COI-5P sequence
  filter(markercode == "COI-5P") %>%
  #Filter out sequences with fewer than 500 base pairs 
  filter(nchar(gsub("-", "", nucleotides)) > 499) %>%
  #Filter out records without a species name
  filter(!is.na(species_name))

#Filter out high gap/N content. A threshold of 1% was chosen because species often differ by more than 2% divergence. By filtering out records with > 1% N and gap content, we are likely to get a high-quality data set, given typical patterns of variability in COI in animals. 
startNGap <- sapply(regmatches(dfData$nucleotides, gregexpr("^[-N]", dfData$nucleotides)), length)
startNGap <- foreach(i=1:nrow(dfData)) %do% 
  if (startNGap[[i]]>0) { 
    split <- strsplit(dfData$nucleotides[i], "^[-N]+") 
    dfData$nucleotides[i] <- split[[1]][2]
  }
endNGap <- sapply(regmatches(dfData$nucleotides, gregexpr("[-N]$", dfData$nucleotides)), length)
endNGap <- foreach(i=1:nrow(dfData)) %do%
  if (endNGap[[i]]>0) {
    split <- strsplit(dfData$nucleotides[i], "[-N]+$")
    dfData$nucleotides[i] <- split[[1]][1]
  }
internalNGap <- sapply(regmatches(dfData$nucleotides, gregexpr("[-N]", dfData$nucleotides)), length)
internalNGap <- foreach(i=1:nrow(dfData)) %do%
  which((internalNGap[[i]]/nchar(dfData$nucleotides[i]) > 0.01))
nGapCheck <- sapply(internalNGap, function(x)length(x))
nGapCheck <- which(nGapCheck>0)
dfData <- dfData[-nGapCheck, ]

#Remove redundant "BOLD" section from each row in the BIN column 
dfData$bin_uri <- substr(dfData$bin_uri, 6, 13)

#Filter out sequences without coordinates 
containLatLon <- grep ("[0-9]", dfData$lat)
dfData <- dfData[containLatLon, ]

#Check for stop codons and indels.
#Save sequences to a list 
sequences <- as.list(dfData$nucleotides)
#Save record IDs as list 
processID <- as.list(dfData$processid)
#Look up translation table for your taxa
translation_table <- which_trans_table(taxa)
#Check for insertions and deletions
coi5p_object <- lapply(1:length(sequences), function(i){
  coi5p_pipe(sequences[[i]], trans_table = translation_table, name = processID[[i]])
})
#See which sequences have indels and stop codons and remove these from the list 
indels <- list.exclude(coi5p_object, indel_likely == "TRUE")
stop_codon <- list.exclude(coi5p_object, stop_codons == "TRUE")
#Create a list of processids for remaining sequences
Ids_Filtered_Indels <- lapply(1:length(indels), function(i){
  indels[[i]]$name
})
Ids_Filtered_Stop <- lapply(1:length(indels), function(i){
  indels[[i]]$name
})
#Remove sequences with indels and stop codons from dataset
dfData <- dfData[dfData$processid %in% Ids_Filtered_Indels, ]
dfData <- dfData[dfData$processid %in% Ids_Filtered_Stop, ]

#Run some checks to ensure data is filtered properly
#Find dimensions of dataset
dim(dfData)
#Check that only CO1 is included 
unique(dfData$markercode)
#Check that there are no NAs
sum(is.na(dfData$bin_uri))
sum(is.na(dfData$species_name))
sum(is.na(dfData$nucleotides))
sum(is.na(dfData$lat))
#Find summary of seqeunce lengths 
summary(str_count(dfData$nucleotides))
#Find length of DNA sequences in the dataset 
Sequence_lengths <- str_count(dfData$nucleotides)
#Make a histogram to show the distributions of sequence lengths 
hist(Sequence_lengths, main = paste("Distribution of Sequence Lengths"), xlab = "Sequence Length")

#Filter the GBIF data
#Remove occurrences without a species ID
dfGeoData <- dfGeoData %>%
  filter(!is.na(species))

#Run some checks
#Find dimensions of dataset 
dim(dfGeoData)
#Check that there are no NAs
sum(is.na(dfGeoData$species))

#Reduce datasets to only needed columns 
dfData <- (dfData[, c("processid", "bin_uri", "species_name", "nucleotides", "lat", "lon")])
dfGeoData <- (dfGeoData[, c("gbifID", "species","decimalLatitude", "decimalLongitude")])

#Remove unneeded variables 
rm(endNGap, internalNGap, split, startNGap, containLatLon, i, nGapCheck, Sequence_lengths, coi5p_object, Ids_Filtered_Indels, Ids_Filtered_Stop, indels, processID, sequences, stop_codon, translation_table)

#4.Organizing Data by Clusters----

#If BOLD BINs are being used, the following steps are not needed.
#Place data into clusters using an additional distance threshold. 
#First, prepare the sequences for the alginment 
#Ensure data is set to dataframe format  
dfData <- as.data.frame(dfData)
#Check the class of the object
class(dfData)
#Convert to DNAStringSet format 
dfData$nucleotides <- DNAStringSet(dfData$nucleotides)
#Name the stringset 
names(dfData$nucleotides) <- dfData$processid
#Check that the names are assigned properly
names(dfData$nucleotides)

#Align the sequences. The following parameters were chosen in order to conduct an efficient and accurate alignment. By setting diags to true, the speed of the alignment is increased. The gapopen is set to -3000 in order to reduce the gaps present in the alingment. 
Data_alignment <- muscle::muscle(dfData$nucleotides, diags=TRUE, gapopen=-3000)
#Convert to DNAStringSet format
Data_alignment <- DNAStringSet(Data_alignment)
#Check class of alignment 
class(Data_alignment)

#Save alignment to file so it can be viewed in programs such as MEGA. 
writeXStringSet(Data_alignment, file = region + "_Alignment", format = "fasta")

#View Alignment in browser
BrowseSeqs(Data_alignment)

#Convert to dnaBin format 
dnaBIN <- as.DNAbin(Data_alignment)
#Check that the class is correct
class(dnaBin)

#Create a distance matrix.
distanceMatrix <- dist.dna(dnaBIN, model = model, as.matrix = TRUE, pairwise.deletion = TRUE)

#Cluster the sequences. 
Data_clustered <- IdClusters(distanceMatrix,
                           method = clustering_method,
                           cutoff = clustering_threshold,
                           showPlot = TRUE,
                           type = "both",
                           verbose = TRUE)
#See how many clusters were created
length(unique(unlist(Data_clustered[[1]][1])))

#Extract the clustered dataframe
dfClusters <- Data_clustered[[1]]
#Set record IDs to a column instead of row names
dfClusters$processid <- row.names(dfClusters)
#Add clusters column to origional dataframe
dfData_Clustered <- merge(dfClusters, dfData_stringset, by = "processid")

#Remove any unneeded variables 
rm(Data_alignment, Data_clustered, dfClusters, dfData_alignment, distanceMatrix, dnaBIN, dfData_stringset)

#5.Group by Regions----

#Construct a grid of cells 
Grid <- dgconstruct(spacing=Polygon_Length, metric= TRUE, resround = 'down')

#Find corresponding grid cells for each record
dfData$cell <- dgGEO_to_SEQNUM(Grid, dfData$lon, dfData$lat)$seqnum

#Change nucleotide column back to a character string 
dfData$nucleotides <- as.character(dfData$nucleotides)
#Filter out BINs with less than 20 records and BINs that are only found in one region 
dfData <- dfData %>%
  group_by(bin_uri) %>%
  filter(n() > 19)
#Filter out BINs that are only found in one region
#Convert to datatable 
dfData <- as.data.table(dfData)
#create datatable showing number of regions per BIN 
regions_per_BIN <- dfData[ , .(number_of_regions=length(unique(cell))), by=bin_uri]
#Convert to to dataframe
regions_per_BIN <- as.data.frame(regions_per_BIN)
#Filter down to BINs that are found in at least two regions 
regions_per_BIN <- filter(regions_per_BIN, regions_per_BIN$number_of_regions > 1)
#Create filter reduce main dataframe to only BINs found in regions_per_BIN
BIN_Filter <- which(dfData$bin_uri %in% regions_per_BIN$bin_uri)
#Apply filter 
dfData <- dfData[BIN_Filter, ]

#Filter out regions with less than 10 BINs
#Create datatable showing number of bins per region 
BINs_per_Region <- dfData[ , .(number_of_bins = length(unique(bin_uri))), by = cell]
#Convert to to dataframe
BINs_per_Region <- as.data.frame(BINs_per_Region)
#Filter down to regions that have 10 or more BINs
BINs_per_Region <- filter(BINs_per_Region, BINs_per_Region$number_of_bins > 9)
#Create filter reduce main dataframe to only regions found in BINs_per_Region
Region_Filter <- which(dfData$cell %in% BINs_per_Region$cell)
#Apply filter 
dfData <- dfData[Region_Filter, ]

#Calculate the species abundance for each polygon using the Chao estimator
#Code was based on https://rstudio-pubs-static.s3.amazonaws.com/210859_a0c6a2a199124917a0a0e7d81d34c8dd.html 
#Create a new dataframe with bin_uri and cells
dfRegions <- (dfData[, c("bin_uri", "cell")])
#Add column with the number of each records of each BIN at each site
dfRegions <- dfRegions %>%
  group_by(bin_uri, cell) %>%
  mutate(count=n())
#Filter down to only unique rows 
dfRegions <- filter(unique(dfRegions))
#Format the table so the regions the columns
dfRegions <- pivot_wider(dfRegions, names_from = cell, values_from = count)
#Calculate the Chao Richness for each region
Chao_Results1 <- ChaoRichness(dfRegions$`7478`)
Chao_Results2 <- ChaoRichness(dfRegions$`7721`)
#Plot rarefaction curves 
R_Curve1 <- iNEXT(dfRegions$`7478`, q=0, datatype="abundance")
ggiNEXT(R_Curve1,)
R_Curve2 <- iNEXT(dfRegions$`7721`, q=0, datatype="abundance")
ggiNEXT(R_Curve2,)

#Filter for regions that have at least 70% of their expected species richness
#Sampled_Regions <- which(Chao_Results$Observed/Chao_Results$Estimator >= percent_sampled)
Chao_Results1$Observed/Chao_Results1$Estimator
Chao_Results2$Observed/Chao_Results2$Estimator
#Filter down dfData to only those in Sampled_Regions
#dfData <- dfData[Sampled_Regions$bin_uri, ]

#Count how many regions are included in the dataset
length(unique(dfData$cell))
#Count how many BINs are included in the dataset
length(unique(dfData$bin_uri))

#Split dataframe based on Bin_uri so each BIN can be analyzed individually
BIN_List <- split(dfData, f = dfData$bin_uri)

#Remove unneeded variables 
rm(BINs_per_Region, Chao_Results1, Chao_Results2, dfRegions, Grid, R_Curve1, R_Curve2, regions_per_BIN, BIN_Filter, Region_Filter)

#6.Multiple Sequence Alignment----

#Alignment code was adapted from my previous work which was origionally adapted from Orton et al.(2019) and May et al.(2020). Code from both of these papers is avaliable at https://github.com/m-orton/Evolutionary-Rates-Analysis-Pipeline/blob/master/EvolutionaryComparisonPipelineSmallTaxa.R and https://github.com/jmay29/phylo/blob/master/refSeqTrim.R 
#Align sequences 
RefSeqTrim <- function(x) {
  #Create data frame for reference sequence 
  #This reference sequence was taken from BOLD for Diptera (Record ID: ACGAZ1590-12, BIN:AAA1222).
  dfRefSeq <- data.frame(taxa= taxa, nucleotides= reference_sequence)
  colnames(dfRefSeq)[2] <- "nucleotides"
  #Convert to datatable
  dfRefSeq <- setDT(dfRefSeq)
  dfRefSeq[, "nucleotides":=as.character(nucleotides)]
  #Trim sequences to 620bp
  dfRefSeq[, nucleotides:=substr(nucleotides, 20, nchar(nucleotides)-19)]
  #Check sequence length
  dfRefSeq[, seqLength:=nchar(nucleotides)]
  #Ensure sequences are of character type
  alignmentSeqs <- as.character(x$nucleotides)
  #Name according to process id
  names(alignmentSeqs) <- x$processid
  alignmentref <- as.character(dfRefSeq$nucleotides[1])
  #Name reference sequence 
  names(alignmentref) <- "Reference"
  #Put sequences together
  alignmentSeqsPlusRef <- append(alignmentref, alignmentSeqs)
  #Convert to DNAStringSet 
  DNAStringSet2 <- DNAStringSet(alignmentSeqsPlusRef)
  #Run alignment 
  alignment2 <- muscle::muscle(DNAStringSet2, diags=TRUE, gapopen=-3000)
  #Check alignment 
  classFileNames <- foreach(i=1:nrow(dfRefSeq)) %do% 
    paste("alignmentUntrimmed", dfRefSeq$taxa[i], ".fas", sep="")
  alignmentUntrimmed <- DNAStringSet(alignment2)
  writeXStringSet(alignmentUntrimmed, file=classFileNames[[1]],
                  format = "fasta", width=1500)
  #Find stop and start positions in reference 
  refSeqPos <- which(alignment2@unmasked@ranges@NAMES=="Reference")
  refSeqPos <- alignment2@unmasked[refSeqPos]
  refSeqPosStart <- regexpr("[ACTG]", refSeqPos)
  refSeqPosStart <- as.numeric(refSeqPosStart)
  refSeqPosEnd <- nchar(dfRefSeq$nucleotides[1]) + refSeqPosStart
  refSeqPosEnd <- as.numeric(refSeqPosEnd)
  #Trim sequence
  alignment2Trimmed <- substr(alignment2, refSeqPosStart, refSeqPosEnd)
  #Convert to DNAStringSet
  DNAStringSet3 <- DNAStringSet(alignment2Trimmed)
  #Remove reference sequence 
  refSeqRm <- which(DNAStringSet3@ranges@NAMES=="Reference")
  dnaStringSet3 <- subset(DNAStringSet3[-refSeqRm])
  alignmentOrder <- DNAStringSet3@ranges@NAMES
  #Reorder based on alignment
  x <- x[match(alignmentOrder, x$processid), ]
  #Replace old sequences with new ones 
  trimmedSeqs <- as.character(DNAStringSet3)
  x$nucleotides <- trimmedSeqs
  #Return dataframe with new sequences 
  return(x)
}

#Trim sequences to reference sequence 
Data_Trimmed <- lapply(1:length(BIN_List), function(i){
  RefSeqTrim(BIN_List[[i]])
})
#Remove NAs 
Data_Trimmed <- lapply(1:length(Data_Trimmed), function(i){
  Data_Trimmed[[i]][-c(1), ]
})

#Create final alignment of sequences 
#Create RefSeq data frame
dfRefSeq <- data.frame(taxa= taxa, nucleotides= reference_sequence)

#name nucleotide column and set as character 
colnames(dfRefSeq)[2] <- "nucleotides"
dfRefSeq$nucleotides <- as.character(dfRefSeq$nucleotides) 
#Trim references to standard 620
dfRefSeq$nucleotides <- substr(dfRefSeq$nucleotides, 20, nchar(dfRefSeq$nucleotides)-19) 
#Check sequence length
dfRefSeq$seqLength <- nchar(dfRefSeq$nucleotides)

#Extract sequences and process ID
processID <- lapply(1:length(Data_Trimmed), function(i){
  Data_Trimmed[[i]]$processid
})
Sequences <- lapply(1:length(Data_Trimmed), function(i){
  Data_Trimmed[[i]]$nucleotides
})
SequenceNames <- processID

#Take reference sequences
alignmentref <- as.character(dfRefSeq$nucleotides)
dfRefSeq$reference <- "reference"
#Name reference as a reference
alignmentRefNames <- dfRefSeq$reference
#Merge reference with other sequences
AlignmentSequencePlusRef <-lapply(1:length(Sequences), function(i){
  append(Sequences[[i]], alignmentref)
})

#Merge names together
AlignmentNames <-lapply(1:length(SequenceNames), function(i){
  append(SequenceNames[[i]], alignmentref)
})

#Convert sequences to DNAStringSet format 
dnaStringSet3 <-lapply(1:length(AlignmentSequencePlusRef), function(i){
  DNAStringSet(AlignmentSequencePlusRef[[i]])
})

#Name each sequence 
names(dnaStringSet3) <- c(alignmentNames) 

#Multiple sequence alignment 
alignmentFinal <- muscle(dnaStringSet3, diags=TRUE, gapopen=-3000)

#Convert to dnaStringSet format
dnaStringSet4 <- DNAStringSet(alignmentFinal)

#Save alignment to fasta file. View in another program such as Mega. 
FastaFileName <- paste(taxa, region, ".fas", sep="")
alignmentFinalFasta <- DNAStringSet(alignmentFinal)
writeXStringSet(alignmentFinalFasta, file=FastaFileName, format="fasta", width=1500)

#Convert DNAStringSet to dataframes
dfData_Aligned <- data.frame(seq=as.character(dnaStringSet4), names=names(dnaStringSet4))
#Rename names column
dfData_Aligned$processid <- dfData_Aligned$names
dfData_Aligned <- dfData_Aligned[, c("processid", "seq")]
#Remove reference sequences
reference_filter <- which(!dfData_Aligned$processid == "reference")
dfData_Aligned <- dfData_Aligned[reference_filter, ]

#Merge with the full data.
dfData_Full <- merge(Data, dfData_Aligned, by = "processid")

#Remove reference sequence
rm.sequence.fasta(FastaFileName, FastaFileName, to.rm = "reference")

#Remove unneeded variables 
rm(alignmentFinal, alignmentFinalFasta, dfData_Aligned, dfData_Trimmed, dfRefSeq, dnaStringSet3, dnaStringSet4, AlignmentName, alignmentNames, alignmentRefNames, alignmentSequencesPlusRef, processID, reference_filter, SequenceNames, Sequences)

#7.F-Statistics and Multi-allelic Measures----

#Read in fasta file
seq_multiFas <- read.multiFASTA(FastaFileName)

#Plot the alignment
plot(seq_multiFas, cex = 0.2)
#Remove .fas from locus name
(setLocusNames(seq_multiFas) <- gsub(".fas", "", getLocusNames(seq_multiFas)))

#Convert to genind object
seq_genind <- multidna2genind(seq_multiFas, mlst = TRUE)
#Check class of object
class(seq_genind)
#Look at summary of object 
summary(seq_genind)

#Create dataframe for labels for the genind object
Names <- data.frame(Species = seqs_multiFas@labels, order = 1:length(seqs_multiFas@labels))

#Create dataframe containing only the record id and population 
dfData_Reduced <- dfData[,c("record_id", "Population")]
#Merge the two dataframes by record id
dfData_Reduced <- merge(dfData_Reduced, Names)
#Ensure dataframe is in the same order as the alignment
dfData_Reduced <- dfData_Reduced[order(Data_Reduced$order), ]

#Create dataframe for populations
dfPopulations <- data.frame(Populations = dfData_Reduced$Population)

#Assign populations to genind object
strata(seqs.gid) <- dfPopulations
#Check to make sure populations are assigned properly 
seq_genind$populations
#Specify that we want to compare the populations we inputted
setPop(seqs.gid) <- ~dfPopulations

#Calculate population genetic differentiation. This function finds the expected heterozygosity if there is random mating within sub-populations, the expected heterozygosity if there were random mating across the global population, Nei's Gst, Hedrick's Gst and Jost's D.
diff_stats(seqs.gid)

#Calculate Jost's D
DPairwise <- as.matrix(pairwise_D(seqs.gid))
#Calculate pairwise FST
NeiPairwise <- as.matrix(pairwise_Gst_Nei(seqs.gid))
#Calculate GST
HedrickPairwise <-as.matrix(pairwise_Gst_Hedrick(seqs.gid))

#Plotting the fst matrix
plot(DPairwise)
plot(NeiPairwise)
plot(HedrickPairwise)

#Remove uneeded variables
rm()

#8.Analysis of Molecular Variance (AMOVA)----

#Calculate pairwise genetic distances 
pairwise_dist <- dist.multidna(seq_multiFas, pool = TRUE)

#Calculate Analysis of Molecular Variance 
amova(pairwise_dist ~ dfpopulations, data = strata(seq_genind), nperm = 100)

#Remove unneeded variables 
rm()

#9.Mismatch Distributions----

#Put sequences into DNABin format
#First convert sequences to a DNAStringSet format
Data_StringSet <- DNAStringSet(dfData_Full$seq)
names(Data_StringSet) <- dfData_Full$bin_uri
Data_DNABin <- as.DNAbin(Data_StringSet)
#Check that the format is correct
class(Data_DNABin)

#Calculate mismatch distribution for the sequences and plot a histogram 
MD <- MMD(Data_DNABin, xlab = "Pairwise Distance")

#Remove unneeded variables
rm()

#10.Analysis of Variance (ANOVA)----

#Read in csv file containing trait information and FST values
Trait_Data <- read_csv(file="C:/Users/sammi/OneDrive/Documents/Diptera_Trait_Data.csv")
#Run ANOVAs for all traits compared to FST
ANOVA_Feeding_Adult_FST <- aov(FST ~ adult_diet, data = Trait_Data)
ANOVA_Feeding_Larval_FST <- aov(FST ~ larval_diet, data = Trait_Data)
ANOVA_Habitat_FST <- aov(FST ~ habitat, data = Trait_Data)
ANOVA_Flight_FST <- aov(FST ~ flight_ability, data = Trait_Data)
#Get ANOVA summary 
summary(ANOVA_Habitat_FST)
summary(ANOVA_Feeding_Adult_FST)
summary(ANOVA_Feeding_Larval_FST)
summary(ANOVA_Flight_FST)

#Run ANOVAs for all traits compared to GST
ANOVA_Feeding_Adult_GST <- aov(GST ~ adult_diet, data = Trait_Data)
ANOVA_Feeding_Larval_GST <- aov(GST ~ larval_diet, data = Trait_Data)
ANOVA_Habitat_GST <- aov(GST ~ habitat, data = Trait_Data)
ANOVA_Flight_GST <- aov(GST ~ flight_ability, data = Trait_Data)
#Get ANOVA summary 
summary(ANOVA_Habitat_GST)
summary(ANOVA_Feeding_Adult_GST)
summary(ANOVA_Feeding_Larval_GST)
summary(ANOVA_Flight_GST)

#Run ANOVAs for all traits compared to JD
ANOVA_Feeding_Adult_JD <- aov(JD ~ adult_diet, data = Trait_Data)
ANOVA_Feeding_Larval_JD <- aov(JD ~ larval_diet, data = Trait_Data)
ANOVA_Habitat_JD <- aov(JD ~ habitat, data = Trait_Data)
ANOVA_Flight_JD <- aov(JD ~ flight_ability, data = Trait_Data)
#Get ANOVA summary 
summary(ANOVA_Habitat_JD)
summary(ANOVA_Feeding_Adult_JD)
summary(ANOVA_Feeding_Larval_JD)
summary(ANOVA_Flight_JD)

#Remove unneeded variables 
rm()

#11.Phylogenetic Generalized Least Squares Analysis (PGLS)----

#Read in phylogenetic tree. This tree was created based on the literature and assembled by hand using the program Mesquite
PGLStree <- read.nexus("Diptera_Tree")
#Set branch lengths to one
PGLStree$edge.length <- replicate((length(PGLStree$edge[, 1])), 1)
PGLStree <- force.ultrametric(PGLStree, method="extend")

#Run PGLS for FST
#Set the row names to species names 
Trait_Data <- Trait_Data %>%
  column_to_rownames(var = 'species_name')
#Make sure tree and dataframe are in the same order
Trait_Data <- Trait_Data[match(PGLStree$tip.label, rownames(Trait_Data)), ]
#Run PGLS analysis 
pglsModel_Habitat_FST <- gls(FST ~ habitat, correlation = corBrownian(phy = PGLStree), data = Trait_Data, method = "ML")
pglsModel_Adult_Diet_FST <- gls(FST ~ adult_diet, correlation = corBrownian(phy = PGLStree), data = Trait_Data, method = "ML")
pglsModel_Larval_Diet_FST <- gls(FST ~ larval_diet, correlation = corBrownian(phy = PGLStree), data = Trait_Data, method = "ML")
pglsModel_Flight_FST <- gls(FST ~ flight_ability, correlation = corBrownian(phy = PGLStree), data = Trait_Data, method = "ML")
#Get PGLS summary 
summary(pglsModel_Habitat_FST)
summary(pglsModel_Adult_Diet_FST)
summary(pglsModel_Larval_Diet_FST)
summary(pglsModel_Flight_FST)

#Create boxplots for traits vs. population genetic structure metrics 
plot_Habitat_FST<- boxplot(Trait_Data$FST ~ Trait_Data$habitat)
plot_Adult_Diet_FST <- boxplot(Trait_Data$FST ~ Trait_Data$adult_diet)
plot_Larval_Diet_FST <- boxplot(Trait_Data$FST ~ Trait_Data$larval_diet)
plot_Flight_FST <- boxplot(Trait_Data$FST ~ Trait_Data$flight_ability)

#Run PGLS for GST
pglsModel_Habitat_GST <- gls(GST ~ habitat, correlation = corBrownian(phy = PGLStree), data = Trait_Data, method = "ML")
pglsModel_Adult_Diet_GST <- gls(GST ~ adult_diet, correlation = corBrownian(phy = PGLStree), data = Trait_Data, method = "ML")
pglsModel_Larval_Diet_GST <- gls(GST ~ larval_diet, correlation = corBrownian(phy = PGLStree), data = Trait_Data, method = "ML")
pglsModel_Flight_GST <- gls(GST ~ flight_ability, correlation = corBrownian(phy = PGLStree), data = Trait_Data, method = "ML")
#Get PGLS summary 
summary(pglsModel_Habitat_GST)
summary(pglsModel_Adult_Diet_GST)
summary(pglsModel_Larval_Diet_GST)
summary(pglsModel_Flight_GST)

#Create boxplots for traits vs. population genetic structure metrics 
plot_Habitat_GST<- boxplot(Trait_Data$GST ~ Trait_Data$habitat)
plot_Adult_Diet_GST <- boxplot(Trait_Data$GST ~ Trait_Data$adult_diet)
plot_Larval_Diet_GST <- boxplot(Trait_Data$GST ~ Trait_Data$larval_diet)
plot_Flight_GST <- boxplot(Trait_Data$GST ~ Trait_Data$flight_ability)

#Run PGLS for JD
#Run PGLS analysis 
pglsModel_Habitat_JD <- gls(JD ~ habitat, correlation = corBrownian(phy = PGLStree), data = Trait_Data, method = "ML")
pglsModel_Adult_Diet_JD <- gls(JD ~ adult_diet, correlation = corBrownian(phy = PGLStree), data = Trait_Data, method = "ML")
pglsModel_Larval_Diet_JD <- gls(JD ~ larval_diet, correlation = corBrownian(phy = PGLStree), data = Trait_Data, method = "ML")
pglsModel_Flight_JD <- gls(JD ~ flight_ability, correlation = corBrownian(phy = PGLStree), data = Trait_Data, method = "ML")
#Get PGLS summary 
summary(pglsModel_Habitat_JD)
summary(pglsModel_Adult_Diet_JD)
summary(pglsModel_Larval_Diet_JD)
summary(pglsModel_Flight_JD)

#Create boxplots for traits vs. population genetic structure metrics 
plot_Habitat_JD<- boxplot(Trait_Data$JD ~ Trait_Data$habitat)
plot_Adult_Diet_JD <- boxplot(Trait_Data$JD ~ Trait_Data$adult_diet)
plot_Larval_Diet_JD <- boxplot(Trait_Data$JD ~ Trait_Data$larval_diet)
plot_Flight_JD <- boxplot(Trait_Data$JD ~ Trait_Data$flight_ability)

#Remove unneeded variables 
rm()

#12.Determining Range Size----

#Reduce dfData_Full to needed columns
dfData_Full <- (dfData_Full[, c("processid", "species_name", "lat", "lon")])
dfGeoData <- (dfGeoData[, c("gbifID", "species","decimalLatitude", "decimalLongitude")])
#Rename the columns so that they are consistent across both dataframes 
dfData_Full <- rename(dfData_Full, ID = processid)
dfGeoData <- dfGeoData %>% 
  rename(
    ID = gbifID,
    species_name = species,
    lat = decimalLatitude,
    lon = decimalLongitude
  )
#Combine dataframes
dfRange_Data <- rbind(dfData_Full, dfGeoData)

#Split into list of dataframes by species
Species_List <- split(dfRange_Data, f = dfRange_Data$species_name)
#Find max and min latitude and longitude for each species 
MaxLat <- lapply(1:length(Species_List), function(i){
  max(Species_List[[i]]$lat)
})
MinLat <- lapply(1:length(Species_List), function(i){
  min(Species_List[[i]]$lat)
})
MaxLon <- lapply(1:length(Species_List), function(i){
  max(Species_List[[i]]$lon)
})
MinLon <- lapply(1:length(Species_List), function(i){
  min(Species_List[[i]]$lon)
})
#Find the length and width of each species distribution
Length <- lapply(1:length(MaxLat), function(i){
  MaxLat[[i]] - MinLat[[i]]
})
Width <- lapply(1:length(MaxLon), function(i){
  MaxLon[[i]] - MinLon[[i]]
})
#Find area for each species distribution
Species_Range <- lapply(1:length(Length), function(i){
  Length*Width 
})

#Remove unneeded variables
rm()

#13. Relationship between F-Statistics, Range size and Traits----

#Read in range size data
Range_Data <- read_csv(file="C:/Users/sammi/OneDrive/Documents/Range_Data.csv")

#Run an ANOVA and PGLS to compare range size to traits and population genetic structure 
#Run ANOVA comparing range size to population genetic stucture metrics 
ANOVA_Range_FST <- aov(range_size ~ FST, data = Range_Data)
ANOVA_Range_GST <- aov(range_size ~ GST, data = Range_Data)
ANOVA_Range_JD <- aov(range_size ~ JD, data = Range_Data)
#Get ANOVA summary 
summary(ANOVA_Range_FST)
summary(ANOVA_Range_GST)
summary(ANOVA_Range_JD)

#Run ANOVA comparing range size to traits 
ANOVA_Range_Adult <- aov(range_size ~ adult_diet, data = Range_Data)
ANOVA_Range_Larval <- aov(range_size ~ larval_diet, data = Range_Data)
ANOVA_Range_Habitat<- aov(range_size ~ habitat, data = Range_Data)
ANOVA_Range_Flight <- aov(range_size ~ flight_ability, data = Range_Data)
#Get ANOVA summary 
summary(ANOVA_Range_Habitat)
summary(ANOVA_Range_Adult)
summary(ANOVA_Range_Larval)
summary(ANOVA_Range_Flight)

#Set the row names to species names 
Range_Data <- Range_Data %>%
  column_to_rownames(var = 'species_name')
#Make sure tree and dataframe are in the same order
Range_Data <- Range_Data[match(PGLStree$tip.label, rownames(Range_Data)), ]

#Run PGLS comparing metrics of population genetic structure to range size
pglsModel_Range_FST <- gls(range_size ~ FST, correlation = corBrownian(phy = PGLStree), data = Range_Data, method = "ML")
pglsModel_Range_GST <- gls(range_size ~ GST, correlation = corBrownian(phy = PGLStree), data = Range_Data, method = "ML")
pglsModel_Range_JD <- gls(range_size ~ JD, correlation = corBrownian(phy = PGLStree), data = Range_Data, method = "ML")
#Get PGLS summary 
summary(pglsModel_Range_FST)
summary(pglsModel_Range_GST)
summary(pglsModel_Range_JD)

#Create boxplots for range size vs. population genetic structure metrics 
plot_Range_FST<- boxplot(Range_Data$range_size ~ Range_Data$FST)
plot_Range_GST<- boxplot(Range_Data$range_size ~ Range_Data$GST)
plot_Range_JD<- boxplot(Range_Data$range_size ~ Range_Data$JD)

#Run PGLS analysis 
pglsModel_Range_Habitat <- gls(range_size ~ habitat, correlation = corBrownian(phy = PGLStree), data = Range_Data, method = "ML")
pglsModel_Range_Adult <- gls(range_size ~ adult_diet, correlation = corBrownian(phy = PGLStree), data = Range_Data, method = "ML")
pglsModel_Range_Larval <- gls(range_size ~ larval_diet, correlation = corBrownian(phy = PGLStree), data = Range_Data, method = "ML")
pglsModel_Range_Flight <- gls(range_size ~ flight_ability, correlation = corBrownian(phy = PGLStree), data = Range_Data, method = "ML")
#Get PGLS summary 
summary(pglsModel_Range_Habitat)
summary(pglsModel_Range_Adult)
summary(pglsModel_Range_Larval)
summary(pglsModel_Range_Flight)

#Create boxplots for range size vs. traits
plot_Range_Habitat <- boxplot(Range_Data$range_size ~ Range_Data$habitat)
plot_Range_Adult <- boxplot(Range_Data$range_size ~ Range_Data$adult_diet)
plot_Range_Larval <- boxplot(Range_Data$larval_size ~ Range_Data$larval_diet)
plot_Range_Flight <- boxplot(Range_Data$range_size ~ Range_Data$flight_ability)

#Remove unneeded variable
rm()
